{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anomalous Financial Transaction Detection\n",
    "\n",
    "ë³¸ ëŒ€íšŒì˜ ê³¼ì œëŠ” ê¸ˆìœµ ê±°ë˜ ë°ì´í„°ì—ì„œ **ì´ìƒ ê±°ë˜ë¥¼ íƒì§€í•˜ëŠ” ê¸°ëŠ¥**ì„ ê°œì„ í•˜ê³  í™œìš©ë„ë¥¼ ë†’ì´ëŠ” ë¶„ë¥˜ AIëª¨ë¸ì„ ê°œë°œí•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. \n",
    "\n",
    "íŠ¹íˆ, í´ë˜ìŠ¤ ë¶ˆê· í˜• ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ì˜¤í”ˆì†ŒìŠ¤ ìƒì„±í˜• AI ëª¨ë¸ì„ í™œìš©í•˜ì—¬ ë¶€ì¡±í•œ í´ë˜ìŠ¤ì˜ ë°ì´í„°ë¥¼ ë³´ì™„í•˜ê³ , ì´ë¥¼ í†µí•´ ë¶„ë¥˜ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ê²ƒì´ í•µì‹¬ ëª©í‘œì…ë‹ˆë‹¤. \n",
    "\n",
    "ì´ëŸ¬í•œ ì ‘ê·¼ì„ í†µí•´ ê¸ˆìœµë³´ì•ˆì— íŠ¹í™”ëœ ë°ì´í„° ë¶„ì„ ë° í™œìš© ì—­ëŸ‰ì„ ê°•í™”í•˜ì—¬ ì „ë¬¸ ì¸ë ¥ì„ ì–‘ì„±í•˜ê³ , ê¸ˆìœµê¶Œì˜ AI í™œìš© ì–´ë ¤ì›€ì— ë”°ë¥¸ í•´ê²° ë°©ì•ˆì„ í•¨ê»˜ ëª¨ìƒ‰í•˜ë©° ê¸ˆìœµ ì‚°ì—…ì˜ AI í™œìš© í™œì„±í™”ë¥¼ ì§€ì›í•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì œì¶œ íŒŒì¼ ìƒì„± ê´€ë ¨\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "# ë°ì´í„° ì²˜ë¦¬ ë° ë¶„ì„\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ë¨¸ì‹ ëŸ¬ë‹ ì „ì²˜ë¦¬\n",
    "from sklearn.preprocessing import LabelEncoder, OrdinalEncoder\n",
    "\n",
    "# ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸\n",
    "import xgboost as xgb\n",
    "\n",
    "# í•©ì„± ë°ì´í„° ìƒì„±\n",
    "from sdv.metadata import SingleTableMetadata\n",
    "from sdv.single_table import CTGANSynthesizer\n",
    "\n",
    "# To ignore all warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ìƒì„± ğŸ­"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all = pd.read_csv(\"./train.csv\")\n",
    "test_all = pd.read_csv(\"./test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_all.drop(columns=\"ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"Fraud_Type\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "(*) ë¦¬ë”ë³´ë“œ ì‚°ì‹ ì¤‘ ìƒì„±ë°ì´í„°ì˜ ìµëª…ì„±(TCAP)ì±„ì ì„ ìœ„í•´ ê° í´ë˜ìŠ¤ ë³„ë¡œ 1000ê°œì˜ ìƒì„±ë°ì´í„°ê°€ ë°˜ë“œì‹œ í•„ìš”í•©ë‹ˆë‹¤.\n",
    "(*) ë³¸ ë² ì´ìŠ¤ ë¼ì¸ì—ì„œëŠ” \"Fraud_Type\" 13ì¢…ë¥˜ì— ëŒ€í•´ 1000ê°œì”© , ì´ 13,000ê°œì˜ ë°ì´í„°ë¥¼ ìƒì„±í•  ì˜ˆì •ì…ë‹ˆë‹¤.\n",
    "(*) ë¶„ë¥˜ ëª¨ë¸ ì„±ëŠ¥ ê°œì„ ì„ ìœ„í•´ ìƒì„± ë°ì´í„°ë¥¼ í™œìš©í•˜ëŠ” ê²ƒì—ëŠ” ìƒì„± ë°ì´í„°ì˜ Row ê°œìˆ˜ì— ì œí•œì´ ì—†ìŠµë‹ˆë‹¤. ë‹¨, ë¦¬ë”ë³´ë“œ í‰ê°€ë¥¼ ìœ„í•´ ì œì¶œì„ í•˜ëŠ” ìƒì„± ë°ì´í„° í”„ë ˆì„ì€ ìµëª…ì„±(TCAP) í‰ê°€ë¥¼ ìœ„í•¨ì´ë©°, ìœ„ì˜ ì¡°ê±´ì„ ê°–ì¶˜ ìƒì„± ë°ì´í„°ë¥¼ ì œì¶œí•´ì•¼í•©ë‹ˆë‹¤.\n",
    "'''\n",
    "N_CLS_PER_GEN = 1000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ì´ìƒì¹˜ ì²˜ë¦¬ í•¨ìˆ˜\n",
    "def handle_outliers(series, n_std=3):\n",
    "    mean = series.mean()\n",
    "    std = series.std()\n",
    "    z_scores = np.abs(stats.zscore(series))\n",
    "    return series.mask(z_scores > n_std, mean)\n",
    "\n",
    "# Time_difference ì»¬ëŸ¼ì„ ì´ ì´ˆë¡œ ë³€í™˜ ë° ì´ìƒì¹˜ ì²˜ë¦¬\n",
    "train['Time_difference_seconds'] = pd.to_timedelta(train['Time_difference']).dt.total_seconds()\n",
    "train['Time_difference_seconds'] = handle_outliers(train['Time_difference_seconds'])\n",
    "\n",
    "\n",
    "# ëª¨ë“  Fraud_Type ëª©ë¡ ìƒì„± (m í¬í•¨)\n",
    "fraud_types = train['Fraud_Type'].unique()\n",
    "\n",
    "# ëª¨ë“  í•©ì„± ë°ì´í„°ë¥¼ ì €ì¥í•  DataFrame ì´ˆê¸°í™”\n",
    "all_synthetic_data = pd.DataFrame()\n",
    "\n",
    "N_SAMPLE = 100\n",
    "\n",
    "# ê° Fraud_Typeì— ëŒ€í•´ í•©ì„± ë°ì´í„° ìƒì„± ë° ì €ì¥\n",
    "for fraud_type in tqdm(fraud_types):\n",
    "    \n",
    "    # í•´ë‹¹ Fraud_Typeì— ëŒ€í•œ ì„œë¸Œì…‹ ìƒì„±\n",
    "    subset = train[train[\"Fraud_Type\"] == fraud_type]\n",
    "\n",
    "    # ëª¨ë“  Fraud_Typeì— ëŒ€í•´ 100ê°œì”© ìƒ˜í”Œë§\n",
    "    subset = subset.sample(n=N_SAMPLE, random_state=42)\n",
    "    \n",
    "    # Time_difference ì—´ ì œì™¸ (ì´ˆ ë‹¨ìœ„ë¡œ ë³€í™˜ëœ ì»¬ëŸ¼ë§Œ ì‚¬ìš©)\n",
    "    subset = subset.drop('Time_difference', axis=1)\n",
    "    \n",
    "    # ë©”íƒ€ë°ì´í„° ìƒì„± ë° ëª¨ë¸ í•™ìŠµ\n",
    "    metadata = SingleTableMetadata()\n",
    "\n",
    "    metadata.detect_from_dataframe(subset)\n",
    "    metadata.set_primary_key(None)\n",
    "\n",
    "    # ë°ì´í„° íƒ€ì… ì„¤ì •\n",
    "    column_sdtypes = {\n",
    "        'Account_initial_balance': 'numerical',\n",
    "        'Account_balance': 'numerical',\n",
    "        'Customer_identification_number': 'categorical',  \n",
    "        'Customer_personal_identifier': 'categorical',\n",
    "        'Account_account_number': 'categorical',\n",
    "        'IP_Address': 'ipv4_address',  \n",
    "        'Location': 'categorical',\n",
    "        'Recipient_Account_Number': 'categorical',\n",
    "        'Fraud_Type': 'categorical',\n",
    "        'Time_difference_seconds': 'numerical',\n",
    "        'Customer_Birthyear': 'numerical'\n",
    "    }\n",
    "\n",
    "    # ê° ì»¬ëŸ¼ì— ëŒ€í•´ ë°ì´í„° íƒ€ì… ì„¤ì •\n",
    "    for column, sdtype in column_sdtypes.items():\n",
    "        metadata.update_column(\n",
    "            column_name=column,\n",
    "            sdtype=sdtype\n",
    "        )\n",
    "        \n",
    "    synthesizer = CTGANSynthesizer(\n",
    "                            metadata,\n",
    "                            epochs=100\n",
    "                        )\n",
    "    synthesizer.fit(subset)\n",
    "\n",
    "    synthetic_subset = synthesizer.sample(num_rows=N_CLS_PER_GEN)\n",
    "    \n",
    "    # ìƒì„±ëœ Time_difference_secondsì˜ ì´ìƒì¹˜ ì²˜ë¦¬\n",
    "    synthetic_subset['Time_difference_seconds'] = handle_outliers(synthetic_subset['Time_difference_seconds'])\n",
    "    \n",
    "    # Time_difference_secondsë¥¼ ë‹¤ì‹œ timedeltaë¡œ ë³€í™˜\n",
    "    synthetic_subset['Time_difference'] = pd.to_timedelta(synthetic_subset['Time_difference_seconds'], unit='s')\n",
    "    \n",
    "    # Time_difference_seconds ì»¬ëŸ¼ ì œê±°\n",
    "    synthetic_subset = synthetic_subset.drop('Time_difference_seconds', axis=1)\n",
    "    \n",
    "    # ìƒì„±ëœ ë°ì´í„°ë¥¼ all_synthetic_dataì— ì¶”ê°€\n",
    "    all_synthetic_data = pd.concat([all_synthetic_data, synthetic_subset], ignore_index=True)\n",
    "# ìµœì¢… ê²°ê³¼ í™•ì¸\n",
    "print(\"\\nFinal All Synthetic Data Shape:\", all_synthetic_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_synthetic_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ì›ë³¸ ë°ì´í„°ì™€ concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_train = train_all.drop(columns=\"ID\")\n",
    "train_total = pd.concat([origin_train, all_synthetic_data])\n",
    "train_total.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing 1 : Select x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_total.drop(columns=['Fraud_Type'])\n",
    "train_y = train_total['Fraud_Type']\n",
    "\n",
    "test_x = test_all.drop(columns=['ID'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing 2 : ë²”ì£¼í˜• ë³€ìˆ˜ ì¸ì½”ë”©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le_subclass = LabelEncoder()\n",
    "train_y_encoded = le_subclass.fit_transform(train_y)\n",
    "\n",
    "# ë³€í™˜ëœ ë ˆì´ë¸” í™•ì¸\n",
    "for i, label in enumerate(le_subclass.classes_):\n",
    "    print(f\"ì›ë˜ ë ˆì´ë¸”: {label}, ë³€í™˜ëœ ìˆ«ì: {i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_x\n",
    "# 'Time_difference' ì—´ì„ ë¬¸ìì—´ë¡œ ë³€í™˜\n",
    "train_x['Time_difference'] = train_x['Time_difference'].astype(str)\n",
    "\n",
    "# ë²”ì£¼í˜• ë³€ìˆ˜ ì¸ì½”ë”©\n",
    "categorical_columns = train_x.select_dtypes(include=['object', 'category']).columns\n",
    "ordinal_encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "\n",
    "# í›ˆë ¨ ë°ì´í„° ì¸ì½”ë”©\n",
    "train_x_encoded = train_x.copy()\n",
    "train_x_encoded[categorical_columns] = ordinal_encoder.fit_transform(train_x[categorical_columns])\n",
    "\n",
    "# íŠ¹ì„± ìˆœì„œ ì €ì¥\n",
    "feature_order = train_x_encoded.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ëª¨ë¸ ì •ì˜ ë° í•™ìŠµ\n",
    "model = xgb.XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=6,\n",
    "    random_state=42,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='mlogloss'\n",
    ")\n",
    "model.fit(train_x_encoded[feature_order], train_y_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¸ì½”ë”©\n",
    "test_x_encoded = test_x.copy()\n",
    "test_x_encoded[categorical_columns] = ordinal_encoder.transform(test_x[categorical_columns])\n",
    "\n",
    "\n",
    "# íŠ¹ì„± ìˆœì„œ ë§ì¶”ê¸° ë° ë°ì´í„° íƒ€ì… ì¼ì¹˜\n",
    "test_x_encoded = test_x_encoded[feature_order]\n",
    "for col in feature_order:\n",
    "    test_x_encoded[col] = test_x_encoded[col].astype(train_x_encoded[col].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì˜ˆì¸¡\n",
    "predictions = model.predict(test_x_encoded)\n",
    "predictions_label = le_subclass.inverse_transform(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë¶„ë¥˜ ì˜ˆì¸¡ ê²°ê³¼ ì œì¶œ ë°ì´í„°í”„ë ˆì„(DataFrame)\n",
    "# ë¶„ë¥˜ ì˜ˆì¸¡ ê²°ê³¼ ë°ì´í„°í”„ë ˆì„ íŒŒì¼ëª…ì„ ë°˜ë“œì‹œ clf_submission.csv ë¡œ ì§€ì •í•´ì•¼í•©ë‹ˆë‹¤.\n",
    "clf_submission = pd.read_csv(\"./sample_submission.csv\")\n",
    "clf_submission[\"Fraud_Type\"] = predictions_label\n",
    "clf_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•©ì„± ë°ì´í„° ìƒì„± ê²°ê³¼ ì œì¶œ ë°ì´í„°í”„ë ˆì„(DataFrame)\n",
    "# í•©ì„± ë°ì´í„° ìƒì„± ê²°ê³¼ ë°ì´í„°í”„ë ˆì„ íŒŒì¼ëª…ì„ ë°˜ë“œì‹œ syn_submission.csv ë¡œ ì§€ì •í•´ì•¼í•©ë‹ˆë‹¤.\n",
    "all_synthetic_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "(*) ì €ì¥ ì‹œ ê° íŒŒì¼ëª…ì„ ë°˜ë“œì‹œ í™•ì¸í•´ì£¼ì„¸ìš”.\n",
    "    1. ë¶„ë¥˜ ì˜ˆì¸¡ ê²°ê³¼ ë°ì´í„°í”„ë ˆì„ íŒŒì¼ëª… = clf_submission.csv\n",
    "    2. í•©ì„± ë°ì´í„° ìƒì„± ê²°ê³¼ ë°ì´í„°í”„ë ˆì„ íŒŒì¼ëª… = syn_submission.csv\n",
    "\n",
    "(*) ì œì¶œ íŒŒì¼(zip) ë‚´ì— ë‘ ê°œì˜ ë°ì´í„°í”„ë ˆì„ì´ ê°ê° ìœ„ì˜ íŒŒì¼ëª…ìœ¼ë¡œ ë°˜ë“œì‹œ ì¡´ì¬í•´ì•¼í•©ë‹ˆë‹¤.\n",
    "(*) íŒŒì¼ëª…ì„ ì¼ì¹˜ì‹œí‚¤ì§€ ì•Šìœ¼ë©´ ì±„ì ì´ ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤.\n",
    "'''\n",
    "\n",
    "# í´ë” ìƒì„± ë° ì‘ì—… ë””ë ‰í† ë¦¬ ë³€ê²½\n",
    "os.makedirs('./submission', exist_ok=True)\n",
    "os.chdir(\"./submission/\")\n",
    "\n",
    "# CSV íŒŒì¼ë¡œ ì €ì¥\n",
    "clf_submission.to_csv('./clf_submission.csv', encoding='UTF-8-sig', index=False)\n",
    "all_synthetic_data.to_csv('./syn_submission.csv', encoding='UTF-8-sig', index=False)\n",
    "\n",
    "# ZIP íŒŒì¼ ìƒì„± ë° CSV íŒŒì¼ ì¶”ê°€\n",
    "with zipfile.ZipFile(\"../baseline_submission.zip\", 'w') as submission:\n",
    "    submission.write('clf_submission.csv')\n",
    "    submission.write('syn_submission.csv')\n",
    "    \n",
    "print('Done.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gimin_py38",
   "language": "python",
   "name": "gimin_py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
